import streamlit as st
import os
import io
import base64
import json
import hashlib
from typing import List, Dict, Any
from PIL import Image
from openai import OpenAI
from pypdf import PdfReader
import chromadb
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

APP_TITLE = "ğŸ“„ AI ê²°ì¬ ì‚¬ì „ê²€í† "

st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

# -------------------- Chroma ì´ˆê¸°í™” --------------------
DB_DIR = "./chroma_db"
chroma_client = chromadb.PersistentClient(path=DB_DIR)
GUIDE_COLLECTION_NAME = "company_guideline"


# -------------------- PDF â†’ í…ìŠ¤íŠ¸ --------------------
def pdf_to_text(file: bytes) -> str:
    reader = PdfReader(io.BytesIO(file))
    texts = [page.extract_text() or "" for page in reader.pages]
    return "\n".join(texts)


# -------------------- í…ìŠ¤íŠ¸ â†’ ì²­í¬ --------------------
def split_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    text = text.replace("\r", "\n")
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        if chunk.strip():
            chunks.append(chunk)
        start = end - overlap
    return chunks


# -------------------- ì„ë² ë”© --------------------
def embed_texts(texts: List[str], api_key: str) -> List[List[float]]:
    if not texts:
        return []
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    return embedder.embed_documents(texts)


# -------------------- Chroma ì €ì¥ --------------------
def save_guideline_to_chroma(chunks: List[str], embeddings: List[List[float]]):
    if not chunks or not embeddings:
        st.error("ê°€ì´ë“œë¼ì¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ëª» ë½‘ì•˜ì–´ìš”.")
        return
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    col.delete(where={"source": "guideline"})
    ids = [f"guide_{i}" for i in range(len(chunks))]
    metas = [{"source": "guideline", "chunk": i} for i in range(len(chunks))]
    col.add(ids=ids, documents=chunks, metadatas=metas, embeddings=embeddings)
    st.success(f"ê°€ì´ë“œë¼ì¸ {len(chunks)}ê°œ ì €ì¥ ì™„ë£Œ âœ…")


def save_caution_to_chroma(chunks: List[str], embeddings: List[List[float]]):
    if not chunks or not embeddings:
        st.error("ìœ ì˜ì‚¬í•­ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ëª» ë½‘ì•˜ì–´ìš”.")
        return
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    col.delete(where={"source": "caution"})
    base = 10_000
    ids = [f"caution_{base + i}" for i in range(len(chunks))]
    metas = [{"source": "caution", "chunk": i} for i in range(len(chunks))]
    col.add(ids=ids, documents=chunks, metadatas=metas, embeddings=embeddings)
    st.success(f"ìœ ì˜ì‚¬í•­ {len(chunks)}ê°œ ì €ì¥ ì™„ë£Œ âœ…")


# -------------------- Chroma ê²€ìƒ‰ --------------------
def search_guideline(query: str, api_key: str, k: int = 4) -> List[Dict[str, Any]]:
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    q_emb = embedder.embed_query(query)
    result = col.query(query_embeddings=[q_emb], n_results=k)
    docs = []
    for i in range(len(result["documents"][0])):
        docs.append({"text": result["documents"][0][i], "metadata": result["metadatas"][0][i]})
    return docs


# -------------------- Vision: ì´ë¯¸ì§€ â†’ JSON --------------------
def pil_to_b64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")


def gpt_extract_table(api_key: str, img: Image.Image, model: str = "gpt-4o") -> Dict[str, Any]:
    """
    - í‘œ ì•ˆ 'ì œëª©' ìš°ì„ , ì—†ìœ¼ë©´ ìƒë‹¨ í° ì œëª©
    - ê²°ì¬ì„  ë¬´ì‹œ
    - ì²¨ë¶€/ì¦ë¹™ ê´€ë ¨ ìˆ˜ì¹˜ëŠ” attachment_count
    """
    client = OpenAI(api_key=api_key)
    img_b64 = pil_to_b64(img)

    system_msg = (
        "ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ë¬¸ì„œë¥¼ í‘œë¡œ ì½ì–´ JSONìœ¼ë¡œ ë§Œë“œëŠ” AIë‹¤. "
        "í‘œ ì•ˆ ì œëª©ì€ ë°˜ë“œì‹œ 'ì œëª©'ìœ¼ë¡œ ë„£ê³ , ê²°ì¬ì„ ì€ ë¬´ì‹œí•˜ê³ , ì²¨ë¶€ ê°œìˆ˜ëŠ” 'attachment_count'ë¡œ ë„£ì–´ë¼."
    )
    user_msg = (
        "ì•„ë˜ ê·œì¹™ìœ¼ë¡œ JSONì„ ë§Œë“¤ì–´ë¼.\n"
        "1) í‘œì— 'ì œëª©' ì…€/ì—´ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„ JSONì˜ 'ì œëª©'ìœ¼ë¡œ.\n"
        "2) ì—†ìœ¼ë©´ ìƒë‹¨ í° ì œëª©ì„ 'ì œëª©'ìœ¼ë¡œ.\n"
        "3) ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹  ë°•ìŠ¤ëŠ” ë¬´ì‹œí•˜ê±°ë‚˜ 'approval_line_ignored': trueë§Œ.\n"
        "4) 'ì²¨ë¶€','ì²¨ë¶€ ê°œìˆ˜','ì¦ë¹™ ê°œìˆ˜','ì˜ìˆ˜ì¦ ê±´ìˆ˜' ë“±ì€ ìˆ«ìë§Œ ëª¨ì•„ 'attachment_count'ì—.\n"
        "5) ë‚˜ë¨¸ì§€ í‘œ ì…€ë„ key-valueë¡œ ìµœëŒ€í•œ í¬í•¨.\n"
        "6) JSONë§Œ ë°˜í™˜."
    )

    resp = client.chat.completions.create(
        model=model,
        temperature=0,
        messages=[
            {"role": "system", "content": system_msg},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_msg},
                    {"type": "image_url", "image_url": {"url": img_b64}},
                ],
            },
        ],
    )

    content = resp.choices[0].message.content.strip()
    if content.startswith("```"):
        content = content.strip("`").replace("json", "", 1).strip()

    try:
        data = json.loads(content)
    except Exception:
        data = {"_raw": content}

    if "ì œëª©" not in data:
        data["ì œëª©"] = ""
    if "attachment_count" not in data:
        data["attachment_count"] = 0
    return data


# -------------------- LLM ë¹„êµ (ì „ì²´ ì¶œë ¥ ë²„ì „) --------------------
def compare_doc_with_guideline(
    api_key: str,
    doc_json: Dict[str, Any],
    guideline_chunks: List[str],
    model: str = "gpt-4o",
) -> str:
    llm = ChatOpenAI(model=model, temperature=0.0, api_key=api_key, max_tokens=2200)

    MAX_GUIDE = 12
    guideline_text = "\n\n".join(guideline_chunks[:MAX_GUIDE])
    user_doc_text = json.dumps(doc_json, ensure_ascii=False, indent=2)

    prompt = f"""
ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ì„œë¥˜ë¥¼ ì‚¬ì „ ê²€í† í•˜ëŠ” AIë‹¤.

[íšŒì‚¬ ê°€ì´ë“œë¼ì¸ ë° ìœ ì˜ì‚¬í•­ ì¼ë¶€ (ìµœëŒ€ {MAX_GUIDE}ê°œ)]
{guideline_text}

[ì‚¬ìš©ìê°€ ì œì¶œí•œ ê²°ì¬ ì„œë¥˜(JSON)]
{user_doc_text}

ìš”êµ¬ì‚¬í•­:
1. ë°œê²¬í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ìœ„ë°˜Â·ëˆ„ë½Â·í˜•ì‹ì˜¤ë¥˜ë¥¼ ì „ë¶€ ë‚˜ì—´í•´ë¼.
2. íŠ¹íˆ ë‹¤ìŒì€ ë°˜ë“œì‹œ ì²´í¬:
   - 'ì œëª©'ì´ ë¹„ì–´ ìˆê±°ë‚˜ ë¶ˆì™„ì „í•œì§€
   - attachment_countê°€ 0ì¸ë° ë¬¸ì„œ ë‚´ìš©ì— 'ì¶œì¥','ë²•ì¸ì¹´ë“œ','ê°œì¸ì¹´ë“œ','ê²½ë¹„','ì§€ê¸‰ìš”ì²­','ì¦ë¹™','ì˜ìˆ˜ì¦' ë“±ì´ ìˆëŠ”ì§€
   - í•„ìˆ˜ í•„ë“œ(ì§€ê¸‰ìš”ì²­ì¼, ì¦ë¹™ìœ í˜•, ì¹´ë“œë‚´ì—­ ë“±)ê°€ ë¹„ì–´ìˆëŠ”ì§€
3. ê²°ì¬ì„ (ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹ )ì€ ë¬¸ì œë¡œ ì‚¼ì§€ ë§ˆë¼.
4. ì¶œë ¥ í˜•ì‹:

- í•­ëª©ëª…: ...
- ë¬¸ì œì : ...
- ìˆ˜ì • ì˜ˆì‹œ: ...

- í•­ëª©ëª…: ...
- ë¬¸ì œì : ...
- ìˆ˜ì • ì˜ˆì‹œ: ...
"""
    res = llm.invoke(prompt)
    return res.content if hasattr(res, "content") else str(res)


# ============================ UI ============================
with st.sidebar:
    st.subheader("ğŸ”‘ OpenAI ì„¤ì •")
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=os.environ.get("OPENAI_API_KEY", ""),
    )
    model = st.selectbox("GPT Vision / LLM ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)

col1, col2 = st.columns([1.1, 0.9])

# ------------ ì™¼ìª½: ì—…ë¡œë“œ ------------
with col1:
    st.subheader("â‘  ê°€ì´ë“œë¼ì¸ PDF ì—…ë¡œë“œ")
    pdf_file = st.file_uploader("ê°€ì´ë“œë¼ì¸ PDF", type=["pdf"], key="guide_pdf")
    if pdf_file is not None and st.button("ê°€ì´ë“œë¼ì¸ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        if not api_key:
            st.error("ë¨¼ì € API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            raw = pdf_to_text(pdf_file.read())
            chunks = split_text(raw, chunk_size=800, overlap=120)
            embs = embed_texts(chunks, api_key)
            save_guideline_to_chroma(chunks, embs)
            st.session_state["guideline_ready"] = True

    st.subheader("â‘¡ ìœ ì˜ì‚¬í•­ PDF ì—…ë¡œë“œ")
    caution_pdf = st.file_uploader("ìœ ì˜ì‚¬í•­ PDF", type=["pdf"], key="caution_pdf")
    if caution_pdf is not None and st.button("ìœ ì˜ì‚¬í•­ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        if not api_key:
            st.error("ë¨¼ì € API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            raw = pdf_to_text(caution_pdf.read())
            chunks = split_text(raw, chunk_size=800, overlap=100)
            embs = embed_texts(chunks, api_key)
            save_caution_to_chroma(chunks, embs)
            st.session_state["caution_ready"] = True

    st.subheader("â‘¢ ê²°ì¬/ê²½ë¹„ ì„œë¥˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    img_file = st.file_uploader("ì´ë¯¸ì§€ (jpg/png)", type=["jpg", "jpeg", "png"], key="doc_img")

    # ì—…ë¡œë“œ ì‹œ ìë™ ì¸ì‹
    if img_file is not None:
        img_bytes = img_file.getvalue()
        img_hash = hashlib.md5(img_bytes).hexdigest()

        st.image(Image.open(io.BytesIO(img_bytes)), caption="ì—…ë¡œë“œí•œ ê²°ì¬ ë¬¸ì„œ", use_container_width=True)

        need_run = st.session_state.get("last_img_hash") != img_hash or "doc_json" not in st.session_state

        if not api_key:
            st.warning("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif need_run:
            with st.spinner("GPTê°€ ë¬¸ì„œ ì¸ì‹ ì¤‘..."):
                doc_img = Image.open(io.BytesIO(img_bytes))
                doc_json = gpt_extract_table(api_key, doc_img, model=model)
            st.session_state["doc_json"] = doc_json
            st.session_state["last_img_hash"] = img_hash
            st.success("ë¬¸ì„œ ì¸ì‹ ì™„ë£Œ âœ…")

        if "doc_json" in st.session_state:
            st.code(json.dumps(st.session_state["doc_json"], ensure_ascii=False, indent=2), language="json")
            st.info(f"ğŸ“ ì¸ì‹ëœ ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {st.session_state['doc_json'].get('attachment_count', 0)}")

# ------------ ì˜¤ë¥¸ìª½: ë¹„êµ ------------
with col2:
    st.subheader("â‘£ ê°€ì´ë“œë¼ì¸ + ìœ ì˜ì‚¬í•­ê³¼ ë¹„êµ")
    if st.button("ìë™ ê²€í†  ì‹¤í–‰"):
        if not api_key:
            st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            doc_json = st.session_state.get("doc_json")
            if not doc_json:
                st.error("ë¨¼ì € ê²°ì¬ ì„œë¥˜ ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ê³  ì¸ì‹í•˜ì„¸ìš”.")
            else:
                guide_qs = [
                    "ì¶œì¥ë¹„ìš©ì§€ê¸‰í’ˆì˜ ì‘ì„± ì‹œ í•„ìˆ˜ í•­ëª©ì€ ë¬´ì—‡ì¸ê°€",
                    "ì§€ê¸‰ìš”ì²­ì¼ ì…ë ¥ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€",
                    "ì¦ë¹™ìœ í˜•, ì¹´ë“œë‚´ì—­ ì…ë ¥ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€",
                ]
                caution_qs = [
                    "ê²½ë¹„ì²­êµ¬ ì‹œ ì£¼ì˜í•´ì•¼ í•  ì‚¬í•­",
                    "í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¹„ìš©ê³¼ ì˜ˆì™¸ ê·œì •",
                ]
                attach_qs = [
                    "ì˜ìˆ˜ì¦, ì¹´ë“œì „í‘œ, ì²¨ë¶€íŒŒì¼ì— ëŒ€í•œ ê·œì¹™",
                    "ë²•ì¸ì¹´ë“œ ë˜ëŠ” ê°œì¸ì¹´ë“œ ì‚¬ìš© ì‹œ í•„ìš”í•œ ì²¨ë¶€ ì„œë¥˜",
                ]

                retrieved_texts: List[str] = []
                for q in guide_qs:
                    for r in search_guideline(q, api_key, k=3):
                        if r["metadata"].get("source") == "guideline":
                            retrieved_texts.append(r["text"])
                for q in caution_qs:
                    for r in search_guideline(q, api_key, k=3):
                        if r["metadata"].get("source") == "caution":
                            retrieved_texts.append(r["text"])
                for q in attach_qs:
                    for r in search_guideline(q, api_key, k=2):
                        retrieved_texts.append(r["text"])

                if not retrieved_texts:
                    st.error("ê°€ì´ë“œë¼ì¸/ìœ ì˜ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì„ë² ë”©í•˜ì„¸ìš”.")
                else:
                    with st.spinner("ê°€ì´ë“œë¼ì¸ê³¼ ë¹„êµ ì¤‘... (ëª¨ë“  ìœ„ë°˜ì‚¬í•­ì„ ì°¾ëŠ” ì¤‘)"):
                        answer = compare_doc_with_guideline(api_key, doc_json, retrieved_texts, model=model)

                    st.success("ê²€í†  ì™„ë£Œ âœ…")
                    st.markdown("**ê²€í†  ê²°ê³¼**")
                    st.write(answer)

                    payload = {
                        "doc_json": doc_json,
                        "retrieved_guideline_texts": retrieved_texts,
                        "analysis": answer,
                    }
                    st.download_button(
                        "ê²€í†  ê²°ê³¼(JSON) ë‹¤ìš´ë¡œë“œ",
                        data=json.dumps(payload, ensure_ascii=False, indent=2),
                        file_name="guideline_check_result.json",
                        mime="application/json",
                    )
