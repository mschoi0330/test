import streamlit as st
import os
import io
import base64
import json
from typing import List, Dict, Any
from PIL import Image
from openai import OpenAI
from pypdf import PdfReader
import chromadb
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

APP_TITLE = "ğŸ“„ AI ê²°ì¬ ì‚¬ì „ê²€í†  (ì œëª©+ì²¨ë¶€íŒŒì¼ ì¸ì‹ ìë™íŒë‹¨)"

DB_DIR = "./chroma_db"
chroma_client = chromadb.PersistentClient(path=DB_DIR)
GUIDE_COLLECTION_NAME = "company_guideline"


# -------------------- ê³µí†µ ìœ í‹¸ --------------------
def pdf_to_text(file: bytes) -> str:
    reader = PdfReader(io.BytesIO(file))
    texts = [page.extract_text() or "" for page in reader.pages]
    return "\n".join(texts)


def split_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    text = text.replace("\r", "\n")
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        if chunk.strip():
            chunks.append(chunk)
        start = end - overlap
    return chunks


def embed_texts(texts: List[str], api_key: str) -> List[List[float]]:
    if not texts:
        return []
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    vectors = embedder.embed_documents(texts)
    return vectors


# -------------------- Chroma ì €ì¥ --------------------
def save_guideline_to_chroma(chunks: List[str], embeddings: List[List[float]]):
    if not chunks or not embeddings:
        st.error("ê°€ì´ë“œë¼ì¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìŠ¤ìº”ë³¸ì´ê±°ë‚˜ ë¹ˆ ë¬¸ì„œì¼ ìˆ˜ ìˆì–´ìš”)")
        return
    collection = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    collection.delete(where={"source": "guideline"})
    ids = [f"guide_{i}" for i in range(len(chunks))]
    metadatas = [{"source": "guideline", "chunk": i} for i in range(len(chunks))]
    collection.add(ids=ids, documents=chunks, metadatas=metadatas, embeddings=embeddings)
    st.success(f"ê°€ì´ë“œë¼ì¸ {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ âœ…")


def save_caution_to_chroma(chunks: List[str], embeddings: List[List[float]]):
    if not chunks or not embeddings:
        st.error("ìœ ì˜ì‚¬í•­ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    collection = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    collection.delete(where={"source": "caution"})
    base_idx = 10_000
    ids = [f"caution_{base_idx + i}" for i in range(len(chunks))]
    metadatas = [{"source": "caution", "chunk": i} for i in range(len(chunks))]
    collection.add(ids=ids, documents=chunks, metadatas=metadatas, embeddings=embeddings)
    st.success(f"ìœ ì˜ì‚¬í•­ {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ âœ…")


def search_guideline(query: str, api_key: str, k: int = 4) -> List[Dict[str, Any]]:
    collection = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    q_emb = embedder.embed_query(query)
    result = collection.query(query_embeddings=[q_emb], n_results=k)
    docs = []
    for i in range(len(result["documents"][0])):
        docs.append({"text": result["documents"][0][i], "metadata": result["metadatas"][0][i]})
    return docs


# -------------------- GPT Vision --------------------
def pil_to_b64(pil_img: Image.Image) -> str:
    buf = io.BytesIO()
    pil_img.save(buf, format="PNG")
    return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")


def gpt_extract_table(api_key: str, pil_img: Image.Image, model: str = "gpt-4o") -> Dict[str, Any]:
    """
    - í‘œ ì•ˆì˜ 'ì œëª©' ì…€ì„ ìµœìš°ì„ ìœ¼ë¡œ ì¸ì‹
    - ìƒë‹¨ í° ì œëª©ì€ fallback
    - ê²°ì¬ì„ ì€ ë¬´ì‹œ
    - 'ì²¨ë¶€'ë‚˜ 'ì¦ë¹™ ê°œìˆ˜' ê´€ë ¨ ì¹¸ì´ ìˆìœ¼ë©´ ìˆ«ìë¥¼ attachment_countë¡œ ì¶”ì¶œ
    """
    client = OpenAI(api_key=api_key)
    img_b64 = pil_to_b64(pil_img)

    system_msg = (
        "ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ë¬¸ì„œë¥¼ í‘œë¡œ ì½ì–´ JSONìœ¼ë¡œ ë§Œë“œëŠ” AIë‹¤. "
        "í‘œ ì•ˆ ì œëª©ì€ ë°˜ë“œì‹œ 'ì œëª©' í‚¤ë¡œ, ì²¨ë¶€ ê°œìˆ˜ëŠ” 'attachment_count'ë¡œ ë½‘ì•„ë¼. "
        "ê²°ì¬ì„ (ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹ )ì€ ë¬´ì‹œí•œë‹¤."
    )
    user_msg = (
        "ë‹¤ìŒ ê·œì¹™ìœ¼ë¡œ JSONì„ ë§Œë“¤ì–´:\n"
        "1. í‘œ ì•ˆì— 'ì œëª©'ì´ë¼ëŠ” ì…€ ì´ë¦„ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„ JSONì˜ 'ì œëª©'ìœ¼ë¡œ ë„£ì–´.\n"
        "2. í‘œ ì•ˆì— 'ì œëª©'ì´ ì—†ìœ¼ë©´ ë¬¸ì„œ ìƒë‹¨ì˜ í° ì œëª©(ì˜ˆ: ì¶œì¥ë¹„ìš©ì§€ê¸‰í’ˆì˜)ì„ 'ì œëª©'ìœ¼ë¡œ ë„£ì–´.\n"
        "3. ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹  ì¹¸ì€ ë¬´ì‹œí•˜ê±°ë‚˜ 'approval_line_ignored': trueë¡œë§Œ ë‚¨ê²¨.\n"
        "4. 'ì²¨ë¶€', 'ì²¨ë¶€íŒŒì¼', 'ì²¨ë¶€ ê°œìˆ˜', 'ì¦ë¹™ ê°œìˆ˜', 'ì˜ìˆ˜ì¦ ê±´ìˆ˜' ê°™ì€ ì¹¸ì´ ìˆìœ¼ë©´ "
        "ìˆ«ìë§Œ ë½‘ì•„ì„œ 'attachment_count': <ìˆ«ì> ë¡œ ë„£ì–´. ìˆ«ìê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ.\n"
        "5. í‘œì— ìˆëŠ” ë‚˜ë¨¸ì§€ ê°’ë“¤ë„ key-valueë¡œ ìµœëŒ€í•œ ë„£ì–´.\n"
        "6. JSONë§Œ ì¶œë ¥í•´."
    )

    resp = client.chat.completions.create(
        model=model,
        temperature=0,
        messages=[
            {"role": "system", "content": system_msg},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_msg},
                    {"type": "image_url", "image_url": {"url": img_b64}},
                ],
            },
        ],
    )

    content = resp.choices[0].message.content.strip()
    if content.startswith("```"):
        content = content.strip("`").replace("json", "", 1).strip()

    try:
        data = json.loads(content)
    except Exception:
        data = {"_raw": content}

    if "ì œëª©" not in data:
        data["ì œëª©"] = ""
    if "attachment_count" not in data:
        data["attachment_count"] = 0
    return data


# -------------------- LLM ë¹„êµ --------------------
def compare_doc_with_guideline(api_key: str, doc_json: Dict[str, Any], guideline_chunks: List[str], model: str = "gpt-4o") -> str:
    llm = ChatOpenAI(model=model, temperature=0.0, api_key=api_key)
    guideline_text = "\n\n".join(guideline_chunks)
    user_doc_text = json.dumps(doc_json, ensure_ascii=False, indent=2)

    prompt = f"""
ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ì„œë¥˜ë¥¼ ì‚¬ì „ ê²€í† í•˜ëŠ” AIì•¼.

[íšŒì‚¬ ê°€ì´ë“œë¼ì¸ ë° ìœ ì˜ì‚¬í•­ ë‚´ìš©]
{guideline_text}

[ì‚¬ìš©ì ë¬¸ì„œ(JSON)]
{user_doc_text}

ê²€í†  ê¸°ì¤€:
1. 'ì œëª©' í•„ë“œëŠ” ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•œë‹¤. ë¹„ì–´ ìˆìœ¼ë©´ 'ì œëª© ëˆ„ë½'ìœ¼ë¡œ ì§€ì í•˜ë¼.
2. attachment_countê°€ 0ì¸ë° ë¬¸ì„œ ë‚´ìš©ì— 'ì¶œì¥', 'ë²•ì¸ì¹´ë“œ', 'ê°œì¸ì¹´ë“œ', 'ì¦ë¹™', 'ì˜ìˆ˜ì¦', 'ì§€ê¸‰ìš”ì²­' ë“±ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 'ì¦ë¹™ ì²¨ë¶€ ëˆ„ë½'ìœ¼ë¡œ ì§€ì í•˜ë¼.
3. ê²°ì¬ì„ (ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹ )ì€ ë¬´ì‹œí•œë‹¤.
4. ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ë¼:

- í•­ëª©ëª…: ...
- ë¬¸ì œì : ...
- ìˆ˜ì • ì˜ˆì‹œ: ...

'ê°€ì´ë“œë¼ì¸ ê·¼ê±°' ê°™ì€ ë¬¸êµ¬ëŠ” ì“°ì§€ ë§ˆ.
"""
    res = llm.invoke(prompt)
    return res.content if hasattr(res, "content") else str(res)


# -------------------- Streamlit UI --------------------
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)
st.caption("í‘œ ì œëª©Â·ì²¨ë¶€íŒŒì¼ ìë™ ì¸ì‹ + ê°€ì´ë“œë¼ì¸/ìœ ì˜ì‚¬í•­ ê¸°ë°˜ ê²€í† ")

with st.sidebar:
    st.subheader("ğŸ”‘ OpenAI ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password", value=os.environ.get("OPENAI_API_KEY", ""))
    model = st.selectbox("GPT Vision / LLM ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)
    st.markdown("---")
    st.info("ê°€ì´ë“œë¼ì¸ê³¼ ìœ ì˜ì‚¬í•­ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”.")

col1, col2 = st.columns([1.1, 0.9])

# ì™¼ìª½
with col1:
    st.subheader("â‘  ê°€ì´ë“œë¼ì¸ PDF ì—…ë¡œë“œ")
    pdf_file = st.file_uploader("ê°€ì´ë“œë¼ì¸ PDF", type=["pdf"], key="guide_pdf")
    if pdf_file is not None and st.button("ê°€ì´ë“œë¼ì¸ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        if not api_key:
            st.error("ë¨¼ì € OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            raw_text = pdf_to_text(pdf_file.read())
            chunks = split_text(raw_text, chunk_size=800, overlap=120)
            embeddings = embed_texts(chunks, api_key)
            save_guideline_to_chroma(chunks, embeddings)
            st.session_state["guideline_ready"] = True

    st.subheader("â‘¡ ìœ ì˜ì‚¬í•­ PDF ì—…ë¡œë“œ")
    caution_pdf = st.file_uploader("ìœ ì˜ì‚¬í•­ PDF", type=["pdf"], key="caution_pdf")
    if caution_pdf is not None and st.button("ìœ ì˜ì‚¬í•­ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        raw_text = pdf_to_text(caution_pdf.read())
        chunks = split_text(raw_text, chunk_size=800, overlap=100)
        embeddings = embed_texts(chunks, api_key)
        save_caution_to_chroma(chunks, embeddings)
        st.session_state["caution_ready"] = True

    st.subheader("â‘¢ ê²°ì¬ ë¬¸ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    img_file = st.file_uploader("ê²°ì¬ ì„œë¥˜ ì´ë¯¸ì§€ (jpg/png)", type=["jpg", "jpeg", "png"], key="doc_img")
    if img_file is not None:
        doc_img = Image.open(img_file)
        st.image(doc_img, caption="ì—…ë¡œë“œí•œ ê²°ì¬ ë¬¸ì„œ", use_column_width=True)
        if st.button("ì´ë¯¸ì§€ì—ì„œ í‘œ/ì œëª©/ì²¨ë¶€ ì¸ì‹", type="primary"):
            with st.spinner("GPTê°€ ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
                doc_json = gpt_extract_table(api_key, doc_img, model=model)
            st.session_state["doc_json"] = doc_json
            st.success("ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ âœ…")
            st.code(json.dumps(doc_json, ensure_ascii=False, indent=2), language="json")
            if "attachment_count" in doc_json:
                st.info(f"ì¸ì‹ëœ ì²¨ë¶€íŒŒì¼ ê°œìˆ˜: {doc_json['attachment_count']}")

# ì˜¤ë¥¸ìª½
with col2:
    st.subheader("â‘£ ê°€ì´ë“œë¼ì¸ + ìœ ì˜ì‚¬í•­ ë¹„êµ")
    if st.button("ìë™ ê²€í†  ì‹¤í–‰"):
        doc_json = st.session_state.get("doc_json")
        if not doc_json:
            st.error("ë¨¼ì € ê²°ì¬ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•˜ì„¸ìš”.")
        else:
            guide_queries = [
                "ì¶œì¥ë¹„ìš©ì§€ê¸‰í’ˆì˜ ì‘ì„± ì‹œ í•„ìˆ˜ í•­ëª©ì€ ë¬´ì—‡ì¸ê°€",
                "ë²•ì¸ì¹´ë“œ/ê°œì¸ì¹´ë“œ ì‚¬ìš© ì‹œ ì¦ë¹™ ì²¨ë¶€ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€",
                "ì§€ê¸‰ìš”ì²­ì¼ ì…ë ¥ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€",
            ]
            caution_queries = ["ê²½ë¹„ì²­êµ¬ ì‹œ ì£¼ì˜ì‚¬í•­", "í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¹„ìš© í•­ëª©"]

            docs: List[str] = []
            for q in guide_queries + caution_queries:
                found = search_guideline(q, api_key, k=2)
                for f in found:
                    docs.append(f["text"])

            with st.spinner("ê°€ì´ë“œë¼ì¸/ìœ ì˜ì‚¬í•­ ê¸°ë°˜ ê²€í†  ì¤‘..."):
                answer = compare_doc_with_guideline(api_key, doc_json, docs, model=model)

            st.success("ê²€í†  ì™„ë£Œ âœ…")
            st.markdown("**ê²€í†  ê²°ê³¼**")
            st.write(answer)

            st.download_button(
                "ê²€í†  ê²°ê³¼(JSON) ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(
                    {"doc_json": doc_json, "guideline_texts": docs, "analysis": answer},
                    ensure_ascii=False,
                    indent=2,
                ),
                file_name="guideline_check_result.json",
                mime="application/json",
            )
