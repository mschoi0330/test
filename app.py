import streamlit as st
import os
import io
import base64
import json
import hashlib
import re
from typing import List, Dict, Any

from PIL import Image, ImageOps, ImageFilter, ImageEnhance
from openai import OpenAI
from pypdf import PdfReader
import chromadb
from langchain_openai import OpenAIEmbeddings, ChatOpenAI


APP_TITLE = "ğŸ“„ AI ê²°ì¬ ì‚¬ì „ê²€í† "

st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

# -------------------- Chroma ì´ˆê¸°í™” --------------------
DB_DIR = "./chroma_db"
chroma_client = chromadb.PersistentClient(path=DB_DIR)
GUIDE_COLLECTION_NAME = "company_guideline"


# -------------------- PDF â†’ í…ìŠ¤íŠ¸ --------------------
def pdf_to_text(file: bytes) -> str:
    reader = PdfReader(io.BytesIO(file))
    texts = [page.extract_text() or "" for page in reader.pages]
    return "\n".join(texts)


# -------------------- í…ìŠ¤íŠ¸ â†’ ì²­í¬ --------------------
def split_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    text = text.replace("\r", "\n")
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        if chunk.strip():
            chunks.append(chunk)
        start = end - overlap
    return chunks


# -------------------- ì„ë² ë”© --------------------
def embed_texts(texts: List[str], api_key: str) -> List[List[float]]:
    if not texts:
        return []
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    return embedder.embed_documents(texts)


# -------------------- Chroma ì €ì¥ --------------------
def save_guideline_to_chroma(chunks: List[str], embeddings: List[List[float]]):
    if not chunks or not embeddings:
        st.error("ê°€ì´ë“œë¼ì¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ëª» ë½‘ì•˜ì–´ìš”.")
        return
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    col.delete(where={"source": "guideline"})
    ids = [f"guide_{i}" for i in range(len(chunks))]
    metas = [{"source": "guideline", "chunk": i} for i in range(len(chunks))]
    col.add(ids=ids, documents=chunks, metadatas=metas, embeddings=embeddings)
    st.success(f"ê°€ì´ë“œë¼ì¸ {len(chunks)}ê°œ ì €ì¥ ì™„ë£Œ âœ…")


def save_caution_to_chroma(chunks: List[str], embeddings: List[List[float]]):
    if not chunks or not embeddings:
        st.error("ìœ ì˜ì‚¬í•­ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ëª» ë½‘ì•˜ì–´ìš”.")
        return
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    col.delete(where={"source": "caution"})
    base = 10_000
    ids = [f"caution_{base + i}" for i in range(len(chunks))]
    metas = [{"source": "caution", "chunk": i} for i in range(len(chunks))]
    col.add(ids=ids, documents=chunks, metadatas=metas, embeddings=embeddings)
    st.success(f"ìœ ì˜ì‚¬í•­ {len(chunks)}ê°œ ì €ì¥ ì™„ë£Œ âœ…")


# -------------------- Chroma ê²€ìƒ‰ --------------------
def search_guideline(query: str, api_key: str, k: int = 4) -> List[Dict[str, Any]]:
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    q_emb = embedder.embed_query(query)
    result = col.query(query_embeddings=[q_emb], n_results=k)
    docs = []
    for i in range(len(result["documents"][0])):
        docs.append({"text": result["documents"][0][i], "metadata": result["metadatas"][0][i]})
    return docs


# -------------------- Vision ìœ í‹¸ --------------------
def pil_to_b64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")


# ===== ì¸ì‹ í’ˆì§ˆ ê°œì„ : ì „ì²˜ë¦¬ + ìŠ¤í‚¤ë§ˆ ê³ ì • + 2íŒ¨ìŠ¤ ì¬ì‹œë„ =====
def preprocess_for_ocr(pil: Image.Image) -> Image.Image:
    img = pil.convert("L")  # grayscale
    w, h = img.size
    scale = 1600 / max(w, h)
    if scale > 1.05:
        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)
    img = ImageEnhance.Contrast(img).enhance(1.25)
    img = ImageEnhance.Sharpness(img).enhance(1.4)
    img = ImageOps.autocontrast(img)
    img = img.point(lambda p: 255 if p > 190 else (0 if p < 120 else p))
    return img.convert("RGB")


FIELD_SCHEMA = {
    "ì œëª©": {"required": True, "pattern": r".{2,}"},
    "attachment_count": {"required": True, "pattern": r"^\d+$"},
    "íšŒì‚¬": {"required": True, "pattern": r".{2,}"},
    "ì‚¬ìš©ë¶€ì„œ(íŒ€)": {"required": True, "pattern": r".{1,}"},
    "ì‚¬ìš©ì": {"required": True, "pattern": r".{1,}"},
    "ì§€ê¸‰ì²˜": {"required": False, "pattern": r".*"},
    "ì—…ë¬´ì¶”ì§„ë¹„": {"required": False, "pattern": r"^\d{1,3}(,\d{3})*$"},
    "ê²°ì˜ê¸ˆì•¡": {"required": False, "pattern": r"^\d{1,3}(,\d{3})*$"},
    "ì§€ê¸‰ìš”ì²­ì¼": {"required": False, "pattern": r"^\d{4}-\d{2}-\d{2}(\([^)]+\))?$"},
}

KEY_NORMALIZER = {
    "ì‚¬ìš©ë¶€ì„œ": "ì‚¬ìš©ë¶€ì„œ(íŒ€)",
    "ë¶€ì„œ": "ì‚¬ìš©ë¶€ì„œ(íŒ€)",
    "ì œ ëª©": "ì œëª©",
    "ì œëª© ": "ì œëª©",
    "í•©ê³„": "ê²°ì˜ê¸ˆì•¡",
    "ì´í•©ê³„": "ê²°ì˜ê¸ˆì•¡",
}


def _normalize_keys(d: Dict[str, Any]) -> Dict[str, Any]:
    out = {}
    for k, v in d.items():
        k2 = KEY_NORMALIZER.get(k.strip(), k.strip())
        out[k2] = v
    return out


def _normalize_values(d: Dict[str, Any]) -> Dict[str, Any]:
    out = dict(d)

    def norm_money(s):
        s = str(s).strip()
        s = re.sub(r"[^\d,]", "", s)  # "150,000ì›" -> "150,000"
        if s.isdigit():
            s = f"{int(s):,}"
        return s

    if "ì—…ë¬´ì¶”ì§„ë¹„" in out:
        out["ì—…ë¬´ì¶”ì§„ë¹„"] = norm_money(out["ì—…ë¬´ì¶”ì§„ë¹„"])
    if "ê²°ì˜ê¸ˆì•¡" in out:
        out["ê²°ì˜ê¸ˆì•¡"] = norm_money(out["ê²°ì˜ê¸ˆì•¡"])

    if "ì§€ê¸‰ìš”ì²­ì¼" in out:
        s = str(out["ì§€ê¸‰ìš”ì²­ì¼"])
        s2 = re.sub(r"[./]", "-", s)  # 2025.11.06 â†’ 2025-11-06
        m = re.search(r"(\d{4}-\d{2}-\d{2})(\([^)]+\))?", s2)
        if m:
            out["ì§€ê¸‰ìš”ì²­ì¼"] = m.group(0)

    if "attachment_count" in out:
        m = re.search(r"\d+", str(out["attachment_count"]))
        out["attachment_count"] = int(m.group()) if m else 0

    return out


def _validate_schema(d: Dict[str, Any]) -> Dict[str, Any]:
    notes = []
    for k, rule in FIELD_SCHEMA.items():
        if rule["required"] and (k not in d or str(d[k]).strip() == ""):
            notes.append(f"í•„ìˆ˜ê°’ ëˆ„ë½: {k}")
        if k in d and rule.get("pattern"):
            if not re.fullmatch(rule["pattern"], str(d[k])):
                notes.append(f"í˜•ì‹ ë¶ˆì¼ì¹˜: {k}={d[k]}")
    d["_notes"] = notes
    return d


def _ask_vision(api_key: str, pil_img: Image.Image, model: str, strict_json=True) -> Dict[str, Any]:
    client = OpenAI(api_key=api_key)
    buf = io.BytesIO()
    pil_img.save(buf, format="PNG")
    b64 = "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")

    system_msg = (
        "ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ ì½ì–´ ì •í•´ì§„ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ë°˜í™˜í•˜ëŠ” AIë‹¤. ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•œë‹¤."
    )
    user_msg = (
        "ë‹¤ìŒ í‚¤ë§Œ í¬í•¨í•˜ëŠ” JSONì„ ë°˜í™˜í•´. í‚¤ëŠ” ì •í™•íˆ ì•„ë˜ì™€ ì¼ì¹˜í•´ì•¼ í•œë‹¤.\n"
        + list(FIELD_SCHEMA.keys()).__str__()
        + "\nê·œì¹™:\n"
        "1) í‘œì— 'ì œëª©' ì…€ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„ 'ì œëª©'ì—. ì—†ìœ¼ë©´ ìƒë‹¨ í° ì œëª©ì„ ì‚¬ìš©.\n"
        "2) ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹  ì˜ì—­ì€ ë¬´ì‹œ. í•„ìš” ì‹œ 'approval_line_ignored': trueë¥¼ ì¶”ê°€ ê°€ëŠ¥.\n"
        "3) 'attachment_count'ëŠ” ìˆ«ìë§Œ. í•´ë‹¹ ì¹¸ì´ ì—†ìœ¼ë©´ 0.\n"
        "4) 'ì—…ë¬´ì¶”ì§„ë¹„','ê²°ì˜ê¸ˆì•¡'ì€ ìˆ«ìì™€ ì½¤ë§ˆë§Œ(ì˜ˆ: 150,000).\n"
        "5) 'ì§€ê¸‰ìš”ì²­ì¼'ì€ YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD(ìš”ì¼) í˜•ì‹.\n"
        "6) JSONë§Œ ì¶œë ¥í•´."
    )

    kwargs = dict(
        model=model,
        temperature=0,
        messages=[
            {"role": "system", "content": system_msg},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_msg},
                    {"type": "image_url", "image_url": {"url": b64}},
                ],
            },
        ],
    )
    if strict_json:
        kwargs["response_format"] = {"type": "json_object"}

    resp = client.chat.completions.create(**kwargs)
    content = resp.choices[0].message.content.strip()
    try:
        return json.loads(content)
    except Exception:
        return {"_raw": content}


def gpt_extract_table(api_key: str, pil_img: Image.Image, model: str = "gpt-4o") -> Dict[str, Any]:
    """
    ê°œì„ ëœ 2-íŒ¨ìŠ¤ ì¶”ì¶œ:
    - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    - ê°•ì œ JSON + ìŠ¤í‚¤ë§ˆ ê³ ì •
    - mini â†” 4o êµì°¨ ì¬ì‹œë„ í›„ ì‚¬í›„ ë³´ì •/ê²€ì¦
    """
    img = preprocess_for_ocr(pil_img)

    # 1ì°¨
    data1 = _ask_vision(api_key, img, model=model, strict_json=True)
    # 2ì°¨: ë³´ì¡° ëª¨ë¸ êµì°¨
    alt_model = "gpt-4o-mini" if model == "gpt-4o" else "gpt-4o"
    data2 = _ask_vision(api_key, img, model=alt_model, strict_json=True)

    data1 = _normalize_values(_normalize_keys(data1))
    data2 = _normalize_values(_normalize_keys(data2))

    merged = {}
    for k in FIELD_SCHEMA.keys():
        v1, v2 = data1.get(k), data2.get(k)
        if v1 == v2:
            merged[k] = v1
        else:
            pat = FIELD_SCHEMA[k].get("pattern")
            def ok(v): return bool(re.fullmatch(pat, str(v))) if pat and v is not None else False
            merged[k] = v1 if ok(v1) else (v2 if ok(v2) else (v1 or v2 or ""))

    merged = _validate_schema(merged)

    # ì œëª©/ì²¨ë¶€ ëˆ„ë½ ì‹œ ë§ˆì§€ë§‰ ë°©ì–´ ì¬ì‹œë„
    need_reask = False
    if (not merged.get("ì œëª©")) or (merged.get("attachment_count", 0) == 0):
        data3 = _ask_vision(api_key, img, model=model, strict_json=True)
        data3 = _normalize_values(_normalize_keys(data3))
        for k in ["ì œëª©", "attachment_count"]:
            if (not merged.get(k)) and data3.get(k):
                merged[k] = data3.get(k)
                need_reask = True
    if need_reask:
        merged = _validate_schema(merged)

    return merged


# -------------------- LLM ë¹„êµ (ì „ì²´ ì¶œë ¥ ë²„ì „) --------------------
def compare_doc_with_guideline(
    api_key: str,
    doc_json: Dict[str, Any],
    guideline_chunks: List[str],
    model: str = "gpt-4o",
) -> str:
    llm = ChatOpenAI(model=model, temperature=0.0, api_key=api_key, max_tokens=2200)

    MAX_GUIDE = 12
    guideline_text = "\n\n".join(guideline_chunks[:MAX_GUIDE])
    user_doc_text = json.dumps(doc_json, ensure_ascii=False, indent=2)

    prompt = f"""
ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ì„œë¥˜ë¥¼ ì‚¬ì „ ê²€í† í•˜ëŠ” AIë‹¤.

[íšŒì‚¬ ê°€ì´ë“œë¼ì¸ ë° ìœ ì˜ì‚¬í•­ ì¼ë¶€ (ìµœëŒ€ {MAX_GUIDE}ê°œ)]
{guideline_text}

[ì‚¬ìš©ìê°€ ì œì¶œí•œ ê²°ì¬ ì„œë¥˜(JSON)]
{user_doc_text}

ìš”êµ¬ì‚¬í•­:
1. ë°œê²¬í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ìœ„ë°˜Â·ëˆ„ë½Â·í˜•ì‹ì˜¤ë¥˜ë¥¼ ì „ë¶€ ë‚˜ì—´í•´ë¼.
2. íŠ¹íˆ ë‹¤ìŒì€ ë°˜ë“œì‹œ ì²´í¬:
   - 'ì œëª©'ì´ ë¹„ì–´ ìˆê±°ë‚˜ ë¶ˆì™„ì „í•œì§€
   - attachment_countê°€ 0ì¸ë° ë¬¸ì„œ ë‚´ìš©ì— 'ì¶œì¥','ë²•ì¸ì¹´ë“œ','ê°œì¸ì¹´ë“œ','ê²½ë¹„','ì§€ê¸‰ìš”ì²­','ì¦ë¹™','ì˜ìˆ˜ì¦' ë“±ì´ ìˆëŠ”ì§€
   - í•„ìˆ˜ í•„ë“œ(ì§€ê¸‰ìš”ì²­ì¼, ì¦ë¹™ìœ í˜•, ì¹´ë“œë‚´ì—­ ë“±)ê°€ ë¹„ì–´ìˆëŠ”ì§€
3. ê²°ì¬ì„ (ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹ )ì€ ë¬¸ì œë¡œ ì‚¼ì§€ ë§ˆë¼.
4. ì¶œë ¥ í˜•ì‹:

- í•­ëª©ëª…: ...
- ë¬¸ì œì : ...
- ìˆ˜ì • ì˜ˆì‹œ: ...

- í•­ëª©ëª…: ...
- ë¬¸ì œì : ...
- ìˆ˜ì • ì˜ˆì‹œ: ...
"""
    res = llm.invoke(prompt)
    return res.content if hasattr(res, "content") else str(res)


# ============================ UI ============================
with st.sidebar:
    st.subheader("ğŸ”‘ OpenAI ì„¤ì •")
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=os.environ.get("OPENAI_API_KEY", ""),
    )
    model = st.selectbox("GPT Vision / LLM ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)

col1, col2 = st.columns([1.1, 0.9])

# ------------ ì™¼ìª½: ì—…ë¡œë“œ ------------
with col1:
    st.subheader("â‘  ê°€ì´ë“œë¼ì¸ PDF ì—…ë¡œë“œ")
    pdf_file = st.file_uploader("ê°€ì´ë“œë¼ì¸ PDF", type=["pdf"], key="guide_pdf")
    if pdf_file is not None and st.button("ê°€ì´ë“œë¼ì¸ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        if not api_key:
            st.error("ë¨¼ì € API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            raw = pdf_to_text(pdf_file.read())
            chunks = split_text(raw, chunk_size=800, overlap=120)
            embs = embed_texts(chunks, api_key)
            save_guideline_to_chroma(chunks, embs)
            st.session_state["guideline_ready"] = True

    st.subheader("â‘¡ ìœ ì˜ì‚¬í•­ PDF ì—…ë¡œë“œ")
    caution_pdf = st.file_uploader("ìœ ì˜ì‚¬í•­ PDF", type=["pdf"], key="caution_pdf")
    if caution_pdf is not None and st.button("ìœ ì˜ì‚¬í•­ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        if not api_key:
            st.error("ë¨¼ì € API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            raw = pdf_to_text(caution_pdf.read())
            chunks = split_text(raw, chunk_size=800, overlap=100)
            embs = embed_texts(chunks, api_key)
            save_caution_to_chroma(chunks, embs)
            st.session_state["caution_ready"] = True

    st.subheader("â‘¢ ê²°ì¬/ê²½ë¹„ ì„œë¥˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    img_file = st.file_uploader("ì´ë¯¸ì§€ (jpg/png)", type=["jpg", "jpeg", "png"], key="doc_img")

    # ì—…ë¡œë“œ ì‹œ ìë™ ì¸ì‹
    if img_file is not None:
        img_bytes = img_file.getvalue()
        img_hash = hashlib.md5(img_bytes).hexdigest()

        st.image(Image.open(io.BytesIO(img_bytes)), caption="ì—…ë¡œë“œí•œ ê²°ì¬ ë¬¸ì„œ", use_container_width=True)

        need_run = st.session_state.get("last_img_hash") != img_hash or "doc_json" not in st.session_state

        if not api_key:
            st.warning("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif need_run:
            with st.spinner("GPTê°€ ë¬¸ì„œ ì¸ì‹ ì¤‘..."):
                doc_img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
                doc_json = gpt_extract_table(api_key, doc_img, model=model)
            st.session_state["doc_json"] = doc_json
            st.session_state["last_img_hash"] = img_hash
            st.success("ë¬¸ì„œ ì¸ì‹ ì™„ë£Œ âœ…")

        # ê²°ê³¼ JSONì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ìš”ì²­ ì‚¬í•­)
        if "doc_json" in st.session_state:
            pass  # í™”ë©´ ì¶œë ¥ ìƒëµ

# ------------ ì˜¤ë¥¸ìª½: ë¹„êµ ------------
with col2:
    st.subheader("â‘£ ê°€ì´ë“œë¼ì¸ + ìœ ì˜ì‚¬í•­ê³¼ ë¹„êµ")
    if st.button("ìë™ ê²€í†  ì‹¤í–‰"):
        if not api_key:
            st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            doc_json = st.session_state.get("doc_json")
            if not doc_json:
                st.error("ë¨¼ì € ê²°ì¬ ì„œë¥˜ ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ê³  ì¸ì‹í•˜ì„¸ìš”.")
            else:
                guide_qs = [
                    "ì¶œì¥ë¹„ìš©ì§€ê¸‰í’ˆì˜ ì‘ì„± ì‹œ í•„ìˆ˜ í•­ëª©ì€ ë¬´ì—‡ì¸ê°€",
                    "ì§€ê¸‰ìš”ì²­ì¼ ì…ë ¥ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€",
                    "ì¦ë¹™ìœ í˜•, ì¹´ë“œë‚´ì—­ ì…ë ¥ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€",
                ]
                caution_qs = [
                    "ê²½ë¹„ì²­êµ¬ ì‹œ ì£¼ì˜í•´ì•¼ í•  ì‚¬í•­",
                    "í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¹„ìš©ê³¼ ì˜ˆì™¸ ê·œì •",
                ]
                attach_qs = [
                    "ì˜ìˆ˜ì¦, ì¹´ë“œì „í‘œ, ì²¨ë¶€íŒŒì¼ì— ëŒ€í•œ ê·œì¹™",
                    "ë²•ì¸ì¹´ë“œ ë˜ëŠ” ê°œì¸ì¹´ë“œ ì‚¬ìš© ì‹œ í•„ìš”í•œ ì²¨ë¶€ ì„œë¥˜",
                ]

                retrieved_texts: List[str] = []
                for q in guide_qs:
                    for r in search_guideline(q, api_key, k=3):
                        if r["metadata"].get("source") == "guideline":
                            retrieved_texts.append(r["text"])
                for q in caution_qs:
                    for r in search_guideline(q, api_key, k=3):
                        if r["metadata"].get("source") == "caution":
                            retrieved_texts.append(r["text"])
                for q in attach_qs:
                    for r in search_guideline(q, api_key, k=2):
                        retrieved_texts.append(r["text"])

                if not retrieved_texts:
                    st.error("ê°€ì´ë“œë¼ì¸/ìœ ì˜ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì„ë² ë”©í•˜ì„¸ìš”.")
                else:
                    with st.spinner("ê°€ì´ë“œë¼ì¸ê³¼ ë¹„êµ ì¤‘... (ëª¨ë“  ìœ„ë°˜ì‚¬í•­ì„ ì°¾ëŠ” ì¤‘)"):
                        answer = compare_doc_with_guideline(api_key, doc_json, retrieved_texts, model=model)

                    st.success("ê²€í†  ì™„ë£Œ âœ…")
                    st.markdown("**ê²€í†  ê²°ê³¼**")
                    st.write(answer)

                    payload = {
                        "doc_json": doc_json,
                        "retrieved_guideline_texts": retrieved_texts,
                        "analysis": answer,
                    }
                    st.download_button(
                        "ê²€í†  ê²°ê³¼(JSON) ë‹¤ìš´ë¡œë“œ",
                        data=json.dumps(payload, ensure_ascii=False, indent=2),
                        file_name="guideline_check_result.json",
                        mime="application/json",
                    )
