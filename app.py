# app.py â€” PASS/FAIL ë ˆí¼ëŸ°ìŠ¤ ê¸°ë°˜ "ë¹ˆì¹¸ë§Œ" ì ê²€ + LLM ë³´ì¡°(ì‹ ë¢°ë„/ì„¤ëª…)
import streamlit as st
import os, io, json, re, glob, hashlib, base64
from datetime import datetime
from typing import Dict, Any, List

import numpy as np
from PIL import Image, ImageOps, ImageEnhance
from openai import OpenAI

# ================== ì•± ê¸°ë³¸ ==================
APP_TITLE = "ğŸ“„ ê²°ì¬ ì„œë¥˜ ë¹ˆì¹¸ ì ê²€ (PASS/FAIL ë ˆí¼ëŸ°ìŠ¤ + LLM ë³´ì¡°)"
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

APP_ROOT = os.getcwd()
DATA_DIR = os.path.join(APP_ROOT, "data")
PASS_DIR = os.path.join(DATA_DIR, "pass_json")
FAIL_DIR = os.path.join(DATA_DIR, "fail_json")

def ensure_dirs():
    os.makedirs(PASS_DIR, exist_ok=True)
    os.makedirs(FAIL_DIR, exist_ok=True)

ensure_dirs()

# ================== ìœ í‹¸ ==================
def pil_to_b64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")

# ================== Vision ì „ì²˜ë¦¬/ì¸ì‹ ==================
def preprocess_for_ocr(pil: Image.Image) -> Image.Image:
    img = pil.convert("L")
    w, h = img.size
    scale = 1600 / max(w, h)
    if scale > 1.05:
        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)
    img = ImageEnhance.Contrast(img).enhance(1.25)
    img = ImageEnhance.Sharpness(img).enhance(1.4)
    img = ImageOps.autocontrast(img)
    img = img.point(lambda p: 255 if p > 190 else (0 if p < 120 else p))
    return img.convert("RGB")

# í‘œì¤€ ìŠ¤í‚¤ë§ˆ(í•„ìš”ì‹œ í‚¤ ì¶”ê°€)
FIELD_SCHEMA = {
    "ì œëª©": {"required": True, "pattern": r".{2,}"},
    "attachment_count": {"required": True, "pattern": r"^\d+$"},
    "íšŒì‚¬": {"required": False, "pattern": r".*"},
    "ì‚¬ìš©ë¶€ì„œ(íŒ€)": {"required": False, "pattern": r".*"},
    "ì‚¬ìš©ì": {"required": False, "pattern": r".*"},
    "ì§€ê¸‰ì²˜": {"required": False, "pattern": r".*"},
    "ì—…ë¬´ì¶”ì‹ ë¹„": {"required": False, "pattern": r"^\d{1,3}(,\d{3})*$"},  # ì˜¤íƒˆì ëŒ€ë¹„ìš© ì˜ˆì‹œ í‚¤ ì¶”ê°€ ê°€ëŠ¥
    "ì—…ë¬´ì¶”ì§„ë¹„": {"required": False, "pattern": r"^\d{1,3}(,\d{3})*$"},
    "ê²°ì˜ê¸ˆì•¡": {"required": False, "pattern": r"^\d{1,3}(,\d{3})*$"},
    "ì§€ê¸‰ìš”ì²­ì¼": {"required": False, "pattern": r"^\d{4}-\d{2}-\d{2}(\([^)]+\))?$"},
}

# ë¼ë²¨ ì •ê·œí™”(ë™ì˜ì–´/ì˜¤íƒˆì â†’ í‘œì¤€í‚¤)
KEY_NORMALIZER = {
    "ì‚¬ìš©ë¶€ì„œ": "ì‚¬ìš©ë¶€ì„œ(íŒ€)",
    "ë¶€ì„œ": "ì‚¬ìš©ë¶€ì„œ(íŒ€)",
    "ì œ ëª©": "ì œëª©",
    "ì œëª© ": "ì œëª©",
    "í•©ê³„": "ê²°ì˜ê¸ˆì•¡",
    "ì´í•©ê³„": "ê²°ì˜ê¸ˆì•¡",
    "ì—…ë¬´ì¶”ì‹ ë¹„": "ì—…ë¬´ì¶”ì§„ë¹„",
}

def _normalize_keys(d: Dict[str, Any]) -> Dict[str, Any]:
    out = {}
    for k, v in d.items():
        k2 = KEY_NORMALIZER.get(str(k).strip(), str(k).strip())
        out[k2] = v
    return out

def _normalize_values(d: Dict[str, Any]) -> Dict[str, Any]:
    out = dict(d)
    def norm_money(s):
        s = str(s).strip()
        s = re.sub(r"[^\d,]", "", s)
        if s.isdigit():
            s = f"{int(s):,}"
        return s
    if "ì—…ë¬´ì¶”ì§„ë¹„" in out:
        out["ì—…ë¬´ì¶”ì§„ë¹„"] = norm_money(out["ì—…ë¬´ì¶”ì§„ë¹„"])
    if "ê²°ì˜ê¸ˆì•¡" in out:
        out["ê²°ì˜ê¸ˆì•¡"] = norm_money(out["ê²°ì˜ê¸ˆì•¡"])
    if "ì§€ê¸‰ìš”ì²­ì¼" in out:
        s = str(out["ì§€ê¸‰ìš”ì²­ì¼"])
        s2 = re.sub(r"[./]", "-", s)
        m = re.search(r"(\d{4}-\d{2}-\d{2})(\([^)]+\))?", s2)
        if m:
            out["ì§€ê¸‰ìš”ì²­ì¼"] = m.group(0)
    if "attachment_count" in out:
        m = re.search(r"\d+", str(out["attachment_count"]))
        out["attachment_count"] = int(m.group()) if m else 0
    return out

# ===== Vision í˜¸ì¶œ: (1) ê°’ë§Œ / (2) ì‹ ë¢°ë„ í¬í•¨ =====
def ask_vision_values(api_key: str, pil_img: Image.Image, model: str) -> Dict[str, Any]:
    client = OpenAI(api_key=api_key)
    b64 = pil_to_b64(pil_img)
    sys = "ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥. ì§€ì •ëœ í‚¤ë§Œ í¬í•¨."
    usr = (
        "ì•„ë˜ í‘œì¤€í‚¤ë§Œ í¬í•¨í•˜ëŠ” JSONì„ ë°˜í™˜í•´. í‚¤ ëª©ë¡:\n"
        + list(FIELD_SCHEMA.keys()).__str__()
        + "\nê·œì¹™:\n"
        "1) í‘œì— 'ì œëª©' ì…€ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„ 'ì œëª©'ì—. ì—†ìœ¼ë©´ ìƒë‹¨ í° ì œëª©ì„ ì‚¬ìš©.\n"
        "2) ê²°ì¬/í•©ì˜/ìŠ¹ì¸/ì°¸ì¡°/ìˆ˜ì‹  ì˜ì—­ì€ ë¬´ì‹œ ê°€ëŠ¥.\n"
        "3) 'attachment_count'ëŠ” ìˆ«ìë§Œ. ì—†ìœ¼ë©´ 0.\n"
        "4) 'ì—…ë¬´ì¶”ì§„ë¹„','ê²°ì˜ê¸ˆì•¡'ì€ ìˆ«ìì™€ ì½¤ë§ˆë§Œ(ì˜ˆ: 150,000).\n"
        "5) 'ì§€ê¸‰ìš”ì²­ì¼'ì€ YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD(ìš”ì¼) í˜•ì‹.\n"
        "6) JSONë§Œ ì¶œë ¥."
    )
    resp = client.chat.completions.create(
        model=model, temperature=0,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": sys},
            {"role": "user", "content": [
                {"type": "text", "text": usr},
                {"type": "image_url", "image_url": {"url": b64}},
            ]},
        ],
    )
    return json.loads(resp.choices[0].message.content)

def ask_vision_with_conf(api_key: str, pil_img: Image.Image, model: str) -> Dict[str, Any]:
    client = OpenAI(api_key=api_key)
    b64 = pil_to_b64(pil_img)
    sys = "ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥. ê° í‚¤ëŠ” {'value':..., 'confidence':0~1} í˜•íƒœ."
    usr = (
        "í‘œì¤€í‚¤ë§Œ í¬í•¨:\n" + list(FIELD_SCHEMA.keys()).__str__() +
        "\nê° í•­ëª©ì€ {'value':<ë¬¸ìì—´>, 'confidence':<0~1 float>}.\n"
        "ê·œì¹™: 'ì œëª©' ìš°ì„ , ê²°ì¬ì„  ë¬´ì‹œ, attachment_countëŠ” ìˆ«ì, ë‚ ì§œ/ê¸ˆì•¡ í¬ë§· ë§ì¶”ê¸°."
    )
    resp = client.chat.completions.create(
        model=model, temperature=0,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": sys},
            {"role": "user", "content": [
                {"type": "text", "text": usr},
                {"type": "image_url", "image_url": {"url": b64}},
            ]},
        ],
    )
    return json.loads(resp.choices[0].message.content)

def gpt_extract_table(api_key: str, pil_img: Image.Image, model: str, use_confidence: bool) -> Dict[str, Any]:
    """ì „ì²˜ë¦¬ + 2íŒ¨ìŠ¤(ëª¨ë¸ êµì°¨) + ê°’ ì •ê·œí™”. ì‹ ë¢°ë„ ëª¨ë“œ ì‹œ confidence í¬í•¨ êµ¬ì¡° í—ˆìš©."""
    img = preprocess_for_ocr(pil_img)

    # 1ì°¨
    if use_confidence:
        d1 = ask_vision_with_conf(api_key, img, model)
        d1v = {k: (v.get("value") if isinstance(v, dict) else v) for k, v in d1.items()}
    else:
        d1 = ask_vision_values(api_key, img, model)
        d1v = d1

    # 2ì°¨(êµì°¨ ëª¨ë¸)
    alt = "gpt-4o" if model == "gpt-4o-mini" else "gpt-4o-mini"
    if use_confidence:
        d2 = ask_vision_with_conf(api_key, img, alt)
        d2v = {k: (v.get("value") if isinstance(v, dict) else v) for k, v in d2.items()}
    else:
        d2 = ask_vision_values(api_key, img, alt)
        d2v = d2

    # í‚¤/ê°’ ì •ê·œí™”
    d1v = _normalize_values(_normalize_keys(d1v))
    d2v = _normalize_values(_normalize_keys(d2v))

    # í•„ë“œë³„ ì„ íƒ(íŒ¨í„´ ë§Œì¡± ìš°ì„ )
    merged = {}
    for k in FIELD_SCHEMA.keys():
        v1, v2 = d1v.get(k), d2v.get(k)
        if v1 == v2:
            merged[k] = v1
        else:
            pat = FIELD_SCHEMA[k].get("pattern")
            def ok(v): return bool(re.fullmatch(pat, str(v))) if pat and v is not None else (str(v).strip() != "")
            merged[k] = v1 if ok(v1) else (v2 if ok(v2) else (v1 or v2 or ""))

    # ë°©ì–´: ì œëª©/ì²¨ë¶€ ëˆ„ë½ ì‹œ 1íšŒ ì¬ì§ˆì˜
    if (not merged.get("ì œëª©")) or (merged.get("attachment_count", 0) == 0):
        if use_confidence:
            d3 = ask_vision_with_conf(api_key, img, model)
            d3v = {k: (v.get("value") if isinstance(v, dict) else v) for k, v in d3.items()}
        else:
            d3 = ask_vision_values(api_key, img, model)
            d3v = d3
        d3v = _normalize_values(_normalize_keys(d3v))
        for k in ["ì œëª©", "attachment_count"]:
            if (not merged.get(k)) and d3v.get(k):
                merged[k] = d3v.get(k)

    if "ì œëª©" not in merged: merged["ì œëª©"] = ""
    if "attachment_count" not in merged: merged["attachment_count"] = 0
    return merged

# ================== ë ˆí¼ëŸ°ìŠ¤(ë¹ˆì¹¸ ì „ìš©) ==================
def load_reference_stats_blank_only(pass_dir=PASS_DIR, fail_dir=FAIL_DIR, required_threshold=0.8):
    def _load_all(p):
        out=[]
        for f in glob.glob(os.path.join(p, "*.json")):
            try: out.append(json.load(open(f, "r", encoding="utf-8")))
            except: pass
        return out

    pass_docs = _load_all(pass_dir)
    fail_docs = _load_all(fail_dir)

    # PASSì—ì„œ ì±„ì›Œì§„ ë¹„ìœ¨
    filled_ratio = {}
    if pass_docs:
        keys = set().union(*[d.keys() for d in pass_docs])
        for k in keys:
            vals = [(str(d.get(k, "")).strip() != "") for d in pass_docs]
            if vals:
                filled_ratio[k] = sum(vals) / len(vals)

    # ì‚¬ì‹¤ìƒ í•„ìˆ˜(ê¸°ë³¸ 0.8)
    inferred_required = {k for k, r in filled_ratio.items() if r >= required_threshold}

    # FAILì—ì„œ ìì£¼ ë¹„ëŠ” í•­ëª©(ì°¸ê³ )
    from collections import Counter
    fail_empty_rank = []
    if fail_docs:
        cnt = Counter()
        for d in fail_docs:
            for k, v in d.items():
                if str(v).strip() == "":
                    cnt[k] += 1
        fail_empty_rank = cnt.most_common(10)

    return {
        "inferred_required": inferred_required,
        "pass_count": len(pass_docs),
        "fail_count": len(fail_docs),
        "filled_ratio": filled_ratio,
        "fail_empty_rank": fail_empty_rank,
    }

def report_blanks_only(doc_json: dict, ref_stats: dict):
    """ë ˆí¼ëŸ°ìŠ¤ ê¸°ì¤€ 'ì‚¬ì‹¤ìƒ í•„ìˆ˜' í•„ë“œë§Œ ê²€ì‚¬ â†’ ë¹ˆì¹¸ì´ë©´ ë¦¬í¬íŠ¸"""
    req = ref_stats.get("inferred_required", set())
    issues = []
    for k in sorted(req):
        if str(doc_json.get(k, "")).strip() == "":
            issues.append({"í•­ëª©ëª…": k, "ë¬¸ì œì ": "ë¹ˆì¹¸", "ìˆ˜ì • ì˜ˆì‹œ": f"{k} ê°’ì„ ì…ë ¥í•˜ì„¸ìš”."})
    return issues

# ================== LLM ì„¤ëª…(ì˜µì…˜) ==================
def llm_explain_required(api_key: str, model: str, filled_ratio: dict, topk=5) -> str:
    if not filled_ratio: return ""
    client = OpenAI(api_key=api_key)
    top = sorted(filled_ratio.items(), key=lambda x: -x[1])[:topk]
    prompt = (
        "ë‹¤ìŒ ì±„ì›€ìœ¨ ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì™œ í•´ë‹¹ í•„ë“œë“¤ì„ 'ì‚¬ì‹¤ìƒ í•„ìˆ˜'ë¡œ ë³´ëŠ”ì§€ í•œ ì¤„ ìš”ì•½ì„ ì‘ì„±í•´ì¤˜. "
        "ì‹¤ë¬´ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ, í•œêµ­ì–´, ê°„ê²°í•˜ê²Œ.\n" + json.dumps(top, ensure_ascii=False)
    )
    resp = client.chat.completions.create(
        model=model, temperature=0.2,
        messages=[{"role":"system","content":"ê°„ê²°í•œ í•œêµ­ì–´ ì„¤ëª…ë§Œ ì¶œë ¥"},
                  {"role":"user","content":prompt}]
    )
    return resp.choices[0].message.content.strip()

def llm_explain_blanks(api_key: str, model: str, blanks: List[dict]) -> str:
    if not blanks: return ""
    client = OpenAI(api_key=api_key)
    prompt = (
        "ë‹¤ìŒ í•­ëª©ë“¤ì´ ë¹ˆì¹¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë°”ë¡œ ì±„ìš¸ ìˆ˜ ìˆë„ë¡ ê°„ë‹¨Â·êµ¬ì²´Â·í•œ ì¤„ ê°€ì´ë“œë¡œ ìš”ì•½í•´ì¤˜. "
        "ë¶ˆí•„ìš”í•œ ì„œë¡  ì—†ì´ ëª©ë¡ í˜•íƒœë¡œ.\n" + json.dumps(blanks, ensure_ascii=False)
    )
    resp = client.chat.completions.create(
        model=model, temperature=0.2,
        messages=[{"role":"system","content":"ê°„ê²°í•œ í•œêµ­ì–´ ëª©ë¡ë§Œ ì¶œë ¥"},
                  {"role":"user","content":prompt}]
    )
    return resp.choices[0].message.content.strip()

# ================== ì‚¬ì´ë“œë°” ==================
with st.sidebar:
    st.subheader("ğŸ”‘ OpenAI ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password", value=os.environ.get("OPENAI_API_KEY", ""))
    model_vision = st.selectbox("Vision ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)
    use_confidence = st.toggle("ì‹ ë¢°ë„(Confidence) ëª¨ë“œ ì‚¬ìš©", value=False, help="í•„ë“œë³„ confidence(0~1)ë¥¼ í™œìš©í•œ ë³´ìˆ˜ì  ì²˜ë¦¬")
    st.markdown("---")
    llm_help_on = st.toggle("LLM ì„¤ëª… ìƒì„±(ê¶Œê³ ë¬¸/ì´ìœ ) ì‚¬ìš©", value=False)
    model_text = st.selectbox("ì„¤ëª…ìš© LLM (í…ìŠ¤íŠ¸)", ["gpt-4o-mini", "gpt-4o"], index=0, disabled=not llm_help_on)
    st.markdown("---")
    if st.button("ë ˆí¼ëŸ°ìŠ¤ ë¡œë“œ/ê°±ì‹ "):
        st.session_state["ref_blank"] = load_reference_stats_blank_only()
        rs = st.session_state["ref_blank"]
        st.success(f"ë¡œë“œ ì™„ë£Œ âœ…  PASS={rs['pass_count']}, FAIL={rs['fail_count']}, "
                   f"ì¶”ë¡ ëœ í•„ìˆ˜í•„ë“œ={len(rs['inferred_required'])}")
        if rs["fail_empty_rank"]:
            st.caption("FAILì—ì„œ ìì£¼ ë¹„ë˜ í•„ë“œ: " + ", ".join([k for k,_ in rs["fail_empty_rank"]]))

# ================== ë³¸ë¬¸ ë ˆì´ì•„ì›ƒ ==================
col1, col2 = st.columns([1.1, 0.9])

# -------- ì™¼ìª½: ì—…ë¡œë“œ/ì €ì¥/í™•ì¸(ë²„íŠ¼ 3ê°œ) --------
with col1:
    st.subheader("â‘  ê²°ì¬/ê²½ë¹„ ì„œë¥˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    img_file = st.file_uploader("ì´ë¯¸ì§€ (jpg/png)", type=["jpg","jpeg","png"], key="doc_img")

    if img_file is not None:
        img_bytes = img_file.getvalue()
        img_hash = hashlib.md5(img_bytes).hexdigest()

        preview = Image.open(io.BytesIO(img_bytes)).convert("RGB")
        st.image(preview, caption="ì—…ë¡œë“œí•œ ê²°ì¬ ë¬¸ì„œ", use_container_width=True)

        need_run = st.session_state.get("last_img_hash") != img_hash or "doc_json" not in st.session_state
        if not api_key:
            st.warning("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif need_run:
            with st.spinner("ë¬¸ì„œ ì¸ì‹ ì¤‘..."):
                doc_json = gpt_extract_table(api_key, preview, model=model_vision, use_confidence=use_confidence)
            st.session_state["doc_json"] = doc_json
            st.session_state["last_img_hash"] = img_hash
            st.success("ë¬¸ì„œ ì¸ì‹ ì™„ë£Œ âœ…")

        # === ë²„íŠ¼ 3ê°œ ===
        if "doc_json" in st.session_state:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            b1, b2, b3 = st.columns(3)

            with b1:
                if st.button("PASS ìƒ˜í”Œë¡œ ì €ì¥"):
                    ensure_dirs()
                    path = os.path.join(PASS_DIR, f"pass_{ts}.json")
                    with open(path, "w", encoding="utf-8") as f:
                        json.dump(st.session_state["doc_json"], f, ensure_ascii=False, indent=2)
                    st.success(f"PASS ìƒ˜í”Œ ì €ì¥ ì™„ë£Œ: {path}")

            with b2:
                if st.button("FAIL ìƒ˜í”Œë¡œ ì €ì¥"):
                    ensure_dirs()
                    path = os.path.join(FAIL_DIR, f"fail_{ts}.json")
                    with open(path, "w", encoding="utf-8") as f:
                        json.dump(st.session_state["doc_json"], f, ensure_ascii=False, indent=2)
                    st.success(f"FAIL ìƒ˜í”Œ ì €ì¥ ì™„ë£Œ: {path}")

            with b3:
                if st.button("ì´ ë¬¸ì„œ ë¹ˆì¹¸ í™•ì¸"):
                    # ë ˆí¼ëŸ°ìŠ¤ ìë™ ë¡œë“œ ì‹œë„
                    ref = st.session_state.get("ref_blank")
                    if not ref:
                        st.session_state["ref_blank"] = load_reference_stats_blank_only()
                        ref = st.session_state["ref_blank"]

                    if ref.get("pass_count", 0) + ref.get("fail_count", 0) == 0:
                        st.warning("ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. PASS/FAIL ìƒ˜í”Œì„ ì €ì¥í•œ ë’¤, ì‚¬ì´ë“œë°”ì—ì„œ 'ë ˆí¼ëŸ°ìŠ¤ ë¡œë“œ/ê°±ì‹ 'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                    else:
                        blanks = report_blanks_only(st.session_state["doc_json"], ref)
                        if not blanks:
                            st.success("ë¹ˆì¹¸ ì—†ìŒ âœ… (ë ˆí¼ëŸ°ìŠ¤ ê¸°ì¤€ í•„ìˆ˜í•„ë“œ ëª¨ë‘ ì±„ì›Œì§)")
                        else:
                            st.error(f"ë¹ˆì¹¸ {len(blanks)}ê±´ ë°œê²¬ âŒ")
                            with st.expander("ë¹ˆì¹¸ ìƒì„¸ ë³´ê¸°", expanded=True):
                                for it in blanks:
                                    st.write(f"- **í•­ëª©ëª…**: {it['í•­ëª©ëª…']}\n  - ë¬¸ì œì : {it['ë¬¸ì œì ']}\n  - ìˆ˜ì • ì˜ˆì‹œ: {it['ìˆ˜ì • ì˜ˆì‹œ']}")
                            # (ì˜µì…˜) LLM ì„¤ëª…
                            if llm_help_on and api_key:
                                with st.spinner("LLMì´ ê°„ë‹¨ ê°€ì´ë“œë¥¼ ì‘ì„± ì¤‘..."):
                                    advice = llm_explain_blanks(api_key, model_text, blanks)
                                if advice:
                                    st.markdown("**ğŸ” ì…ë ¥ ê°€ì´ë“œ (LLM ìš”ì•½)**")
                                    st.write(advice)

# -------- ì˜¤ë¥¸ìª½: ë ˆí¼ëŸ°ìŠ¤ í˜„í™©/ì„¤ëª… --------
with col2:
    st.subheader("â‘¡ ë ˆí¼ëŸ°ìŠ¤ í˜„í™© / í•„ìˆ˜ í•„ë“œ ì„¤ëª…")
    ref = st.session_state.get("ref_blank")
    if not ref:
        st.info("ì‚¬ì´ë“œë°”ì˜ [ë ˆí¼ëŸ°ìŠ¤ ë¡œë“œ/ê°±ì‹ ]ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
    else:
        st.write(f"- PASS ìƒ˜í”Œ: **{ref['pass_count']}**ê°œ, FAIL ìƒ˜í”Œ: **{ref['fail_count']}**ê°œ")
        st.write(f"- ì¶”ë¡ ëœ 'ì‚¬ì‹¤ìƒ í•„ìˆ˜' í•„ë“œ ìˆ˜: **{len(ref['inferred_required'])}**ê°œ")
        if ref["inferred_required"]:
            st.write("í•„ìˆ˜ë¡œ ê°„ì£¼ëœ í•„ë“œ ì˜ˆ:", ", ".join(list(ref["inferred_required"])[:8]) + (" ..." if len(ref["inferred_required"])>8 else ""))

        if llm_help_on and api_key and ref.get("filled_ratio"):
            if st.button("í•„ìˆ˜ë¡œ ë³´ëŠ” ì´ìœ  í•œ ì¤„ ì„¤ëª…(LLM)"):
                with st.spinner("LLMì´ ìš”ì•½ ì„¤ëª… ì‘ì„± ì¤‘..."):
                    msg = llm_explain_required(api_key, model_text, ref["filled_ratio"], topk=5)
                if msg:
                    st.markdown("**ğŸ“ ì™œ í•„ìˆ˜ë¡œ ë³´ë‚˜ìš”? (LLM ìš”ì•½)**")
                    st.write(msg)
