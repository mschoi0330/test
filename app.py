import streamlit as st
import os
import io
import json
import base64
from typing import List, Dict, Any
from PIL import Image
from openai import OpenAI
from pypdf import PdfReader
import chromadb
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

# -------------------------------------------------
# ì„¤ì •
# -------------------------------------------------
APP_TITLE = "ğŸ“„ AI ê²°ì¬ ì‚¬ì „ê²€í†  (RAG + PASS/FAIL í•™ìŠµ í†µí•©í˜•)"
DB_DIR = "./chroma_db"
DATASET_PATH = "./pass_fail_dataset.json"

st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

# -------------------------------------------------
# ì´ˆê¸°í™”
# -------------------------------------------------
chroma_client = chromadb.PersistentClient(path=DB_DIR)
GUIDE_COLLECTION_NAME = "company_guideline"

# -------------------------------------------------
# ê³µí†µ ìœ í‹¸
# -------------------------------------------------
def pdf_to_text(file: bytes) -> str:
    reader = PdfReader(io.BytesIO(file))
    texts = [page.extract_text() or "" for page in reader.pages]
    return "\n".join(texts)

def split_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    text = text.replace("\r", "\n")
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        if chunk.strip():
            chunks.append(chunk)
        start = end - overlap
    return chunks

def embed_texts(texts: List[str], api_key: str) -> List[List[float]]:
    if not texts:
        return []
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    return embedder.embed_documents(texts)

def pil_to_b64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")

# -------------------------------------------------
# PDF â†’ Chroma ì €ì¥
# -------------------------------------------------
def save_pdf_to_chroma(chunks: List[str], embeddings: List[List[float]], source: str):
    if not chunks or not embeddings:
        st.error(f"{source} PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    col.delete(where={"source": source})
    base = 10_000 if source == "caution" else 0
    ids = [f"{source}_{base + i}" for i in range(len(chunks))]
    metas = [{"source": source, "chunk": i} for i in range(len(chunks))]
    col.add(ids=ids, documents=chunks, metadatas=metas, embeddings=embeddings)
    st.success(f"{source} {len(chunks)}ê°œ ì €ì¥ ì™„ë£Œ âœ…")

def search_guideline(query: str, api_key: str, k: int = 4) -> List[str]:
    col = chroma_client.get_or_create_collection(GUIDE_COLLECTION_NAME)
    embedder = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)
    q_emb = embedder.embed_query(query)
    result = col.query(query_embeddings=[q_emb], n_results=k)
    texts = []
    for i in range(len(result["documents"][0])):
        texts.append(result["documents"][0][i])
    return texts

# -------------------------------------------------
# Vision: ê²°ì¬ ë¬¸ì„œ ë¶„ì„
# -------------------------------------------------
def gpt_extract_table(api_key: str, img: Image.Image, model: str = "gpt-4o") -> Dict[str, Any]:
    client = OpenAI(api_key=api_key)
    img_b64 = pil_to_b64(img)

    system_msg = (
        "ë„ˆëŠ” íšŒì‚¬ ê²°ì¬/ê²½ë¹„ ë¬¸ì„œë¥¼ í‘œ í˜•íƒœë¡œ ë¶„ì„í•˜ëŠ” AIë‹¤. "
        "ë¬¸ì„œì˜ ì œëª©, ì²¨ë¶€íŒŒì¼ ê°œìˆ˜, ì£¼ìš” í•­ëª©(ì§€ê¸‰ìš”ì²­ì¼, ì¦ë¹™ìœ í˜•, ì¹´ë“œë‚´ì—­ ë“±)ì„ JSONìœ¼ë¡œ ë§Œë“¤ì–´ë¼. "
        "ê²°ì¬ì„ (ê²°ì¬, ìŠ¹ì¸, ì°¸ì¡° ë“±)ì€ ë¬´ì‹œí•˜ê³ , JSONë§Œ ë°˜í™˜í•´ë¼."
    )
    user_msg = (
        "ì•„ë˜ ê²°ì¬ì„œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë§Œë“¤ì–´ë¼.\n"
        "ì˜ˆì‹œ: { 'ì œëª©': 'ì¶œì¥ë¹„ ê²°ì¬ì„œ', 'ì¦ë¹™ìœ í˜•': 'ë²•ì¸ì¹´ë“œ', 'ì²¨ë¶€íŒŒì¼ìˆ˜': 2, 'ì§€ê¸‰ìš”ì²­ì¼': 'ìµì›” 10ì¼' }"
    )

    resp = client.chat.completions.create(
        model=model,
        temperature=0,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": [
                {"type": "text", "text": user_msg},
                {"type": "image_url", "image_url": {"url": img_b64}},
            ]},
        ],
    )

    content = resp.choices[0].message.content.strip()
    if content.startswith("```"):
        content = content.strip("`").replace("json", "", 1).strip()

    try:
        data = json.loads(content)
    except Exception:
        data = {"_raw": content}

    data.setdefault("ì œëª©", "")
    data.setdefault("ì²¨ë¶€íŒŒì¼ìˆ˜", 0)
    return data

# -------------------------------------------------
# PASS / FAIL ë°ì´í„° í•™ìŠµ ì €ì¥
# -------------------------------------------------
def save_pass_fail_data(new_data: List[Dict[str, Any]]):
    if os.path.exists(DATASET_PATH):
        with open(DATASET_PATH, "r", encoding="utf-8") as f:
            existing = json.load(f)
    else:
        existing = []
    existing.extend(new_data)
    with open(DATASET_PATH, "w", encoding="utf-8") as f:
        json.dump(existing, f, ensure_ascii=False, indent=2)
    st.success(f"PASS/FAIL ë°ì´í„° {len(new_data)}ê±´ ì €ì¥ ì™„ë£Œ (ì´ {len(existing)}ê±´) âœ…")

# -------------------------------------------------
# í†µí•© ë¹„êµ (ê°€ì´ë“œë¼ì¸ + íŒ¨í„´ í•™ìŠµ)
# -------------------------------------------------
def integrated_compare(api_key: str, test_json: Dict[str, Any], model: str = "gpt-4o") -> str:
    llm = ChatOpenAI(model=model, temperature=0, api_key=api_key, max_tokens=2500)
    rag_texts = []

    # ê°€ì´ë“œë¼ì¸ê³¼ ìœ ì˜ì‚¬í•­ ê²€ìƒ‰
    for q in ["ì§€ê¸‰ìš”ì²­ì¼ ì…ë ¥ ê·œì¹™", "ì¦ë¹™ìœ í˜• ì…ë ¥ ê·œì¹™", "ì²¨ë¶€íŒŒì¼ ê·œì¹™", "ê²½ë¹„ì²­êµ¬ ì£¼ì˜ì‚¬í•­"]:
        rag_texts.extend(search_guideline(q, api_key, k=2))

    # PASS/FAIL ë°ì´í„° ë¡œë“œ
    if os.path.exists(DATASET_PATH):
        with open(DATASET_PATH, "r", encoding="utf-8") as f:
            dataset = json.load(f)
        pass_data = [d for d in dataset if d.get("ìƒíƒœ") == "PASS"]
        fail_data = [d for d in dataset if d.get("ìƒíƒœ") == "FAIL"]
    else:
        pass_data, fail_data = [], []

    prompt = f"""
ë„ˆëŠ” íšŒì‚¬ ê²°ì¬ ë¬¸ì„œë¥¼ ì‚¬ì „ ê²€í† í•˜ëŠ” AIë‹¤.

[íšŒì‚¬ ê°€ì´ë“œë¼ì¸ ë° ìœ ì˜ì‚¬í•­ ì¼ë¶€]
{json.dumps(rag_texts[:10], ensure_ascii=False, indent=2)}

[PASS ë¬¸ì„œ ì˜ˆì‹œ]
{json.dumps(pass_data[:5], ensure_ascii=False, indent=2)}

[FAIL ë¬¸ì„œ ì˜ˆì‹œ]
{json.dumps(fail_data[:5], ensure_ascii=False, indent=2)}

[ê²€í† í•  ê²°ì¬ ë¬¸ì„œ]
{json.dumps(test_json, ensure_ascii=False, indent=2)}

ìš”êµ¬ì‚¬í•­:
1. ê°€ì´ë“œë¼ì¸ ê·œì • ë° ìœ ì˜ì‚¬í•­ ìœ„ë°˜ ì—¬ë¶€ í™•ì¸.
2. PASS/FAIL í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œì˜ íŒ¨í„´ì„ ë¹„êµ.
3. í•„ìˆ˜ í•­ëª© ëˆ„ë½(ì œëª©, ì¦ë¹™ìœ í˜•, ì²¨ë¶€íŒŒì¼ìˆ˜, ì§€ê¸‰ìš”ì²­ì¼ ë“±) ë° ì²¨ë¶€íŒŒì¼ìˆ˜ 0ì¸ ê²½ìš° FAIL ê°€ëŠ¥ì„± íŒë‹¨.
4. ì¶œë ¥ì€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ.

- í•­ëª©ëª…: ...
- ë¬¸ì œì : ...
- ìˆ˜ì • ì˜ˆì‹œ: ...
ìµœì¢… íŒì •: PASS / FAIL (ì´ìœ  í¬í•¨)
"""
    res = llm.invoke(prompt)
    return res.content if hasattr(res, "content") else str(res)

# -------------------------------------------------
# UI
# -------------------------------------------------
with st.sidebar:
    st.subheader("ğŸ”‘ OpenAI ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password")
    model = st.selectbox("ëª¨ë¸ ì„ íƒ", ["gpt-4o", "gpt-4o-mini"], index=0)
    st.caption("ê°€ì´ë“œë¼ì¸ PDF, PASS/FAIL í•™ìŠµ ë°ì´í„°ë¥¼ ì—…ë¡œë“œ í›„ í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ê²€í† í•˜ì„¸ìš”.")

col1, col2 = st.columns([1.1, 0.9])

# ---------------- ì™¼ìª½: ë°ì´í„° ì—…ë¡œë“œ ----------------
with col1:
    st.header("â‘  ê°€ì´ë“œë¼ì¸ / ìœ ì˜ì‚¬í•­ ì—…ë¡œë“œ")
    pdf_file = st.file_uploader("ê°€ì´ë“œë¼ì¸ PDF", type=["pdf"], key="guide_pdf")
    caution_pdf = st.file_uploader("ìœ ì˜ì‚¬í•­ PDF", type=["pdf"], key="caution_pdf")

    if st.button("PDF ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"):
        if not api_key:
            st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            if pdf_file:
                text = pdf_to_text(pdf_file.read())
                chunks = split_text(text)
                embs = embed_texts(chunks, api_key)
                save_pdf_to_chroma(chunks, embs, "guideline")
            if caution_pdf:
                text = pdf_to_text(caution_pdf.read())
                chunks = split_text(text)
                embs = embed_texts(chunks, api_key)
                save_pdf_to_chroma(chunks, embs, "caution")

    st.header("â‘¡ PASS / FAIL í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ")
    pass_imgs = st.file_uploader("âœ… PASS ë¬¸ì„œ (ì—¬ëŸ¬ì¥ ê°€ëŠ¥)", type=["jpg", "png"], accept_multiple_files=True)
    fail_imgs = st.file_uploader("âŒ FAIL ë¬¸ì„œ (ì—¬ëŸ¬ì¥ ê°€ëŠ¥)", type=["jpg", "png"], accept_multiple_files=True)

    if st.button("PASS/FAIL ë°ì´í„° í•™ìŠµ"):
        if not api_key:
            st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            learned = []
            for img_file in pass_imgs or []:
                img = Image.open(img_file)
                data = gpt_extract_table(api_key, img, model)
                data["ìƒíƒœ"] = "PASS"
                learned.append(data)
            for img_file in fail_imgs or []:
                img = Image.open(img_file)
                data = gpt_extract_table(api_key, img, model)
                data["ìƒíƒœ"] = "FAIL"
                learned.append(data)
            if learned:
                save_pass_fail_data(learned)

    st.header("â‘¢ í…ŒìŠ¤íŠ¸ ê²°ì¬ ë¬¸ì„œ ì—…ë¡œë“œ")
    test_img = st.file_uploader("í…ŒìŠ¤íŠ¸ ë¬¸ì„œ", type=["jpg", "png"], key="test_img")
    if test_img:
        img = Image.open(test_img)
        st.image(img, caption="í…ŒìŠ¤íŠ¸ ë¬¸ì„œ", use_container_width=True)
        if st.button("ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰"):
            test_json = gpt_extract_table(api_key, img, model)
            st.session_state["test_json"] = test_json
            st.success("ë¬¸ì„œ ì¸ì‹ ì™„ë£Œ âœ…")
            st.code(json.dumps(test_json, ensure_ascii=False, indent=2), language="json")

# ---------------- ì˜¤ë¥¸ìª½: ê²°ê³¼ ----------------
with col2:
    st.header("â‘£ AI í†µí•© ê²€í†  ê²°ê³¼")
    if st.button("AI ìë™ ê²€í†  ì‹¤í–‰"):
        if not api_key:
            st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            test_json = st.session_state.get("test_json")
            if not test_json:
                st.error("í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
            else:
                with st.spinner("AIê°€ ê·œì • + í•™ìŠµ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„ ì¤‘..."):
                    result = integrated_compare(api_key, test_json, model)
                st.success("ê²€í†  ì™„ë£Œ âœ…")
                st.markdown("**ê²€í†  ê²°ê³¼ (AI ë¶„ì„)**")
                st.write(result)
